{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdvzXBQMrFY8X3DqLcIexj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiomar73/nlp-google-colab/blob/main/Paraphrase_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "HTFMqydyIwWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "6dJ2KvjsLhMi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.sbert.net/docs/pretrained_models.html\n",
        "\n",
        "Order by Performance Sentence Embeddings (14 Datasets) DESC"
      ],
      "metadata": {
        "id": "tKbBPARdPzoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Name\t                       Sentence Semantic  Perf.   Speed    Size    Scores\n",
        "# sentence-t5-xxl                       70.88    54.40  62.64      50 9230 MB => \n",
        "# gtr-t5-xxl                            70.73    55.76\t63.25      50 9230 MB => \n",
        "# all-roberta-large-v1                  70.23    53.05\t61.64     800\t1360 MB => ['1.00', '0.58', '0.47', '0.30', '-0.05']\n",
        "# all-mpnet-base-v1                     69.98    54.69\t62.34    2800\t 420 MB => ['1.00', '0.62', '0.57', '0.38', ' 0.04']\n",
        "# gtr-t5-large                          69.90    54.85\t62.38     800\t 640 MB => ['1.00', '0.82', '0.81', '0.72', ' 0.49']\n",
        "# gtr-t5-xl                             69.88    55.88\t62.88     230\t2370 MB => ['1.00', '0.76', '0.73', '0.61', ' 0.41']\n",
        "# all-mpnet-base-v2                     69.57    57.02\t63.30    2800\t 420 MB => ['1.00', '0.59', '0.57', '0.42', ' 0.05']\n",
        "# sentence-t5-xl                        69.23    51.19\t60.21     230\t2370 MB => ['1.00', '0.89', '0.87', '0.75', ' 0.60']\n",
        "# all-MiniLM-L12-v1                     68.83    50.78\t59.80    7500\t 120 MB => \n",
        "# sentence-t5-large                     68.74    49.05\t58.89     800\t 640 MB => \n",
        "# all-distilroberta-v1                  68.73    50.94\t59.84    4000\t 290 MB => ['1.00', '0.58', '0.55', '0.32', ' 0.08']\n",
        "# all-MiniLM-L12-v2                     68.70    50.82\t59.76    7500\t 120 MB => \n",
        "# all-MiniLM-L6-v2                      68.06    49.54\t58.80   14200\t  80 MB => \n",
        "# all-MiniLM-L6-v1                      68.03    48.07\t58.05   14200\t  80 MB => \n",
        "# paraphrase-mpnet-base-v2              67.97    47.43\t57.70    2800\t 420 MB => \n",
        "# sentence-t5-base                      67.84    44.63\t56.23    2500\t 210 MB => \n",
        "# gtr-t5-base                           67.65    51.15\t59.40    2500\t 210 MB => \n",
        "# multi-qa-mpnet-base-dot-v1            66.76    57.60\t62.18    2800\t 420 MB => \n",
        "# multi-qa-distilbert-dot-v1            66.67    52.51\t59.59    4000\t 250 MB => \n",
        "# multi-qa-mpnet-base-cos-v1            66.29    57.46\t61.88    2800\t 420 MB => \n",
        "# paraphrase-distilroberta-base-v2      66.27    43.10\t54.69    4000\t 290 MB =>  ['1.00', '0.74', '0.69', '0.39', '-0.03']\n",
        "# paraphrase-TinyBERT-L6-v2             66.19    41.07\t53.63    4500\t 240 MB => \n",
        "# paraphrase-MiniLM-L12-v2              66.01    43.01\t54.51    7500\t 120 MB => \n",
        "# multi-qa-distilbert-cos-v1            65.98    52.83\t59.41    4000\t 250 MB => \n",
        "# paraphrase-multilingual-mpnet-base-v2 65.83    41.68\t53.75    2500\t 970 MB => \n",
        "# paraphrase-MiniLM-L6-v2               64.82    40.31\t52.56   14200\t  80 MB => \n",
        "# paraphrase-albert-small-v2            64.46    40.04\t52.25    5000\t  43 MB => ['1.00', '0.67', '0.52', '0.40', ' 0.03']\n",
        "# multi-qa-MiniLM-L6-cos-v1             64.33    51.83\t58.08   14200\t  80 MB => \n",
        "# paraphrase-multilingual-MiniLM-L12-v2 64.25    39.19\t51.72    7500\t 420 MB => \n",
        "# multi-qa-MiniLM-L6-dot-v1             63.90    49.19\t56.55   14200\t  80 MB => \n",
        "# msmarco-bert-base-dot-v5              62.68    52.11\t57.39    2800\t 420 MB => \n",
        "# msmarco-distilbert-base-tas-b         62.57    49.25\t55.91    4000\t 250 MB => \n",
        "# paraphrase-MiniLM-L3-v2               62.29    39.19\t50.74   19000\t  61 MB => \n",
        "# msmarco-distilbert-dot-v5             61.84    49.47\t55.66    4000\t 250 MB => \n",
        "# distiluse-base-multilingual-cased-v1  61.30    29.87\t45.59    4000\t 480 MB => \n",
        "# distiluse-base-multilingual-cased-v2  60.18    27.35\t43.77    4000\t 480 MB => \n",
        "# average_word_embeddings_komninos      51.13    21.64\t36.39   22000\t 240 MB => \n",
        "# average_word_embeddings_glove.6B.300d 49.79    22.71\t36.25   34000\t 420 MB => "
      ],
      "metadata": {
        "id": "vQgWvWwC4f02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-t5-xl')"
      ],
      "metadata": {
        "id": "NS6LzxL6PqCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsplv8xPGM5E",
        "outputId": "2754452a-42ff-4380-db18-b7c3a6c6b563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: ['1.00', '0.89', '0.87', '0.75', '0.60']\n"
          ]
        }
      ],
      "source": [
        "# Two lists of sentences\n",
        "sentences1 = [\n",
        "  'most advanced conversation intelligence and AI powered coaching platform',\n",
        "  'Oh, so the quantified platform is one of the most advanced communication intelligence in AI powered coaching systems.',\n",
        "  'Oh, so the quantified platform is one of the most advanced communication intelligence in AI powered coaching systems. And what does that really mean? So, um, communication coaching is something that is typically delivered one on one between a communication coach who has a, uh, a doctorate or a, um, background and experience in teaching people how to be better communicators and how to express themselves effectively.',  \n",
        "  'And what does that really mean? So, um, communication coaching is something that is typically delivered one on one between a communication coach who has a, uh, a doctorate or a, um, background and experience in teaching people how to be better communicators and how to express themselves effectively.',\n",
        "  'The new movie is awesome'\n",
        "]\n",
        "sentences2 = [\n",
        "  'most advanced conversation intelligence and AI powered coaching platform',\n",
        "  'most advanced conversation intelligence and AI powered coaching platform',\n",
        "  'most advanced conversation intelligence and AI powered coaching platform',\n",
        "  'most advanced conversation intelligence and AI powered coaching platform',\n",
        "  'most advanced conversation intelligence and AI powered coaching platform',\n",
        "]\n",
        "#Compute embedding for both lists\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "#Compute cosine-similarities\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
        "#Output the pairs with their score\n",
        "#for i in range(len(sentences1)):\n",
        "#  print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i][:50], sentences2[i][:50], cosine_scores[i][i]))\n",
        "print(f\"Scores: { [ f'{cosine_scores[i][i]:.2f}' for i in range(len(sentences1)) ] }\")"
      ]
    }
  ]
}