{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMT/Up05GZ/cp4MKcP5OoP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiomar73/nlp-google-colab/blob/main/nlp_poc_01_classify_transcript_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pY4KuDwmZaD",
        "outputId": "a6c79f48-52f6-467a-dda6-785ac9b46794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.7/dist-packages (0.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.7/dist-packages (from openai) (1.2.0.62)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "\n",
        "import openai\n",
        "\n",
        "openai.organization = \"org-XXXXXXXXXXXXXXXXXXXXX\"\n",
        "openai.api_key = \"sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GMiObOsmpL2",
        "outputId": "92f75cf5-4d94-4b85-b3c8-3bfddc7e7341"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (from gradio) (0.18.3)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.7/dist-packages (from gradio) (2.1.0)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (from gradio) (0.85.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.0)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.8.2)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.15.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.9.2)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (from gradio) (0.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.7/dist-packages (from gradio) (0.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.7/dist-packages (from gradio) (10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.6)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: starlette==0.20.4 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (0.20.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.20.4->fastapi->gradio) (3.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->gradio) (1.3.0)\n",
            "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (0.15.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py~=1.0 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.7/dist-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.2.1)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (38.0.1)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (4.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read saved Categories and Phrases"
      ],
      "metadata": {
        "id": "5ziUGnrouxX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pickle5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm_U58Jbuv_-",
        "outputId": "fdd5dd7a-de07-4dc8-8e25-a0fe46d6126b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle5 as pickle"
      ],
      "metadata": {
        "id": "in1EPJWIu5qX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_phrases_path = './df_phrases.pkl'\n",
        "df_phrases = pd.read_pickle(df_phrases_path)\n",
        "print(df_phrases.shape)\n",
        "df_phrases.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "KMNtK8-Nu9UA",
        "outputId": "e3a75683-fe01-4ee5-db58-b09e9a214b71"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             category label  \\\n",
              "0  What is Quantified  What   \n",
              "1  What is Quantified  What   \n",
              "2  What is Quantified  What   \n",
              "\n",
              "                                             example  \\\n",
              "0  most advanced conversation intelligence and AI...   \n",
              "1  a software platform that helps people reach th...   \n",
              "2                   for communicating and connecting   \n",
              "\n",
              "                                           embedding  \n",
              "0  [-0.007960937917232513, 0.0075285546481609344,...  \n",
              "1  [-0.00591889675706625, 2.6476920538698323e-05,...  \n",
              "2  [-0.005206338595598936, 0.0007997832144610584,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edde64b4-2aea-4fdb-9531-969c5cef0b4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>example</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Quantified</td>\n",
              "      <td>What</td>\n",
              "      <td>most advanced conversation intelligence and AI...</td>\n",
              "      <td>[-0.007960937917232513, 0.0075285546481609344,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Quantified</td>\n",
              "      <td>What</td>\n",
              "      <td>a software platform that helps people reach th...</td>\n",
              "      <td>[-0.00591889675706625, 2.6476920538698323e-05,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is Quantified</td>\n",
              "      <td>What</td>\n",
              "      <td>for communicating and connecting</td>\n",
              "      <td>[-0.005206338595598936, 0.0007997832144610584,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edde64b4-2aea-4fdb-9531-969c5cef0b4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-edde64b4-2aea-4fdb-9531-969c5cef0b4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-edde64b4-2aea-4fdb-9531-969c5cef0b4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Transcript"
      ],
      "metadata": {
        "id": "ssouu33fvOGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def transcript_to_sentences(transcript):\n",
        "  doc = nlp(transcript)\n",
        "  sentences = [ sentence.text for sentence in list(doc.sents) ]\n",
        "  print(sentences[:3])\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "Vb2J8rhOvPOC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-3"
      ],
      "metadata": {
        "id": "jV9p-hjUvs4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def calculate_embeddings_with_gpt3(sentence, engine=\"text-similarity-davinci-001\", interval = 1.5, verbose=True):\n",
        "  if verbose:\n",
        "    print(f'Calculating embedding for {sentence}...')\n",
        "  time.sleep(interval)\n",
        "  response = openai.Embedding.create(\n",
        "    input=sentence,\n",
        "    engine=engine\n",
        "  )\n",
        "  embedding = response['data'][0]['embedding']\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "hvbAq5gBvoU6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio UI"
      ],
      "metadata": {
        "id": "hnVB22qnu-IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def quantified_classification(transcript, threshold):\n",
        "  \n",
        "  df_sentences = pd.DataFrame(columns=['line', 'sentence', 'embedding'])\n",
        "  for idx, sentence in enumerate(transcript_to_sentences(transcript)):\n",
        "    embedding = calculate_embeddings_with_gpt3(sentence)\n",
        "    # Create new row\n",
        "    new_row = {\n",
        "      'line': idx + 1,\n",
        "      'sentence': sentence,\n",
        "      'embedding': embedding\n",
        "    }\n",
        "    df_sentences = df_sentences.append(new_row, ignore_index=True)\n",
        "  # print(df_sentences.shape)\n",
        "  # df_sentences.head()\n",
        "  \n",
        "  targets = np.array([ np.array(value[0]) for value in df_phrases[[\"embedding\"]].values ])\n",
        "  # print(f\"targets:{targets.shape}\")\n",
        "  df_cosines = pd.DataFrame(columns=['line'])\n",
        "\n",
        "  for i, row in df_sentences.iterrows():\n",
        "      line = f'{row[\"line\"]:03}'\n",
        "      # print(f'Calculating cosines for [ {line} ] {row[\"sentence\"][:50]}...')\n",
        "      source = np.array(row[\"embedding\"])\n",
        "      cosine = np.dot(targets,source)/(np.linalg.norm(targets, axis=1)*np.linalg.norm(source))\n",
        "      # Create new row\n",
        "      new_row = dict([(f\"Cosine{f'{key:02}'}\", value) for key, value in enumerate(cosine.flatten(), 1)])\n",
        "      new_row[\"line\"] = row[\"line\"]\n",
        "      df_cosines = df_cosines.append(new_row, ignore_index=True)\n",
        "\n",
        "  df_cosines['line'] = df_cosines['line'].astype('int')\n",
        "  # print(df_cosines.shape)\n",
        "  # df_cosines.head(3)\n",
        "\n",
        "  df_comparison = df_cosines #[(df_cosines.filter(regex='Cosine') > threshold).any(axis=1)]\n",
        "  # print(df_comparison.shape)\n",
        "  # df_comparison.head(3)\n",
        "\n",
        "  threshold = threshold / 100\n",
        "\n",
        "  df_results = pd.DataFrame(columns=['line', 'sentence', 'phrase', 'category', 'tag', 'similarity'])\n",
        "\n",
        "  for i, row in df_comparison.iterrows():\n",
        "    for n in range(1,64+1):\n",
        "      col = f\"Cosine{f'{n:02}'}\"\n",
        "      # if row[col] > threshold:\n",
        "      phrase = df_phrases.loc[[ n - 1 ]]\n",
        "      new_row = { \n",
        "        'line': row[\"line\"],\n",
        "        'sentence': df_sentences.at[int(row[\"line\"])-1,\"sentence\"],\n",
        "        'phrase': df_phrases.at[n-1,\"example\"],\n",
        "        'category': df_phrases.at[n-1,\"category\"],\n",
        "        'tag': df_phrases.at[n-1,\"label\"],\n",
        "        'similarity': row[col]\n",
        "      }\n",
        "      df_results = df_results.append(new_row, ignore_index=True)\n",
        "\n",
        "  df_results['line'] = df_cosines['line'].astype('int')\n",
        "  # print(df_results.shape)\n",
        "  # df_results.head(3)\n",
        "\n",
        "  df_summary = df_results.groupby(['tag'])['similarity'].agg('max').to_frame()\n",
        "  df_summary['ok'] = np.where(df_summary['similarity'] > threshold, True, False)\n",
        "  # df_summary\n",
        "\n",
        "  import plotly.express as px\n",
        "\n",
        "  fig = px.bar(\n",
        "    df_summary,\n",
        "    y='similarity',\n",
        "    color='ok',\n",
        "    color_discrete_map={ True: px.colors.qualitative.Plotly[2], False: px.colors.qualitative.Set2[7] },\n",
        "    text='similarity',\n",
        "    text_auto='.3f',\n",
        "    labels={'tag': 'Category', 'similarity': 'Similarity'},\n",
        "    title = f\"{transcript[:200]}...\"\n",
        "  )\n",
        "  fig.add_shape( # add a horizontal \"target\" line\n",
        "      type=\"line\", line_color=\"salmon\", line_width=3, opacity=1, line_dash=\"dot\",\n",
        "      x0=0, x1=1, xref=\"paper\", y0=threshold, y1=threshold, yref=\"y\"\n",
        "  )\n",
        "  fig.update_traces(textfont_size=24, textangle=0, textposition=\"inside\", cliponaxis=False)\n",
        "  fig.update_yaxes(\n",
        "      range=[0, 1]\n",
        "  )  \n",
        "  # fig.show()\n",
        "\n",
        "  details = df_results.drop(labels='line',axis=1).sort_values(['tag','similarity'],ascending=[True,False]).groupby('tag').head(3).reset_index().drop(labels='index',axis=1)\n",
        "\n",
        "  res = df_summary['similarity'].to_dict()\n",
        "\n",
        "  return res, fig, details\n",
        "\n",
        "demo = gr.Interface(\n",
        "    title=\"Transcript classifier\",\n",
        "    fn=quantified_classification,\n",
        "    inputs=[gr.Textbox(lines=10, placeholder=\"Transcript Here...\"), gr.Slider(0, 100, 80)],\n",
        "    outputs=[\"label\",gr.Plot(),gr.outputs.Dataframe()],\n",
        "    allow_flagging=\"never\",\n",
        "    examples=[\n",
        "      [ \"Hello, how are you doing today? I'm here to tell you a little bit about, uh, quantified communications and the quantified platform and how it impacts organizations, who it helps and how it works. So I'll get started off by telling you just a little bit about a high level about, um, the quantified platform. Oh, so the quantified platform is one of the most advanced communication intelligence in AI powered coaching systems. And what does that really mean? So, um, communication coaching is something that is typically delivered one on one between a communication coach who has a, uh, a doctorate or a, um, background and experience in teaching people how to be better communicators and how to express themselves effectively. Um, those coaches would work one-on-one with individuals, um, maybe put their information in front of audiences and see how well they respond. And that can be a very costly process as well as a time consuming. And, um, not always backed by the science of what really drives great communication. So the quantified platform allows all of that to be automated through our AI coaching system. Um, our system empowers, um, uh, is empowered by behavioral science in order to be able to take videos into the system and be able to render exactly how a audience is going to perceive you and provide the communication feedback that you need in order to be, become a better communicator. So that helps you sell more, that helps drive better experiences and improves your external communication with your clients. So how does it work? Um, I touched on that a little bit, um, but let me kind of unpack exactly the science behind it. Um, so we started off with a, a large swath of videos of from fantastic communicators, all the people that you would idolize and wanna be like, and we took those videos and we put them in front of panelists and we scored them to see exactly how well they would perform in front of an audience. So how likable, uh, uh, was that speaker, um, how effective were they at communicating their ideas? You know, were they persuasive? Would you actually buy something from them? Did you wanna listen to them longer? Um, did you find them engaging? These things are innately human in their, um, in how communication elicits a response from us? Those are the types of things that we actually measured and built an algorithm around. So the way that the system works is it, um, uh, you are allowed to record yourself inside the application. Um, we also embed into video conferencing platforms as well. So you can invite a bot into your live meeting conversations if you wish. And we have other integration options as well, including having a role playing conversations inside the application. Um, once we have that, the system analyzes, uh, the video content for the words that you say, so your sentence structure, phrases, um, sentiment analysis, pronoun usage, ver burb tone and usage. Um, how you conduct your face, the microexpressions that you have, um, do you appear happy, calm, angry, and your gestures? Um, you know, part of being an appealing, um, conversationalist is being engaging and have people want to, <laugh> want to listen to you. And, and so all of these things all come together into really, um, defining what makes a great piece of communication. And we use that as our benchmark of how to define that inside of our platform. So when you go into the platform, you're really being measured against the best communicators, as well as our entire community of people using the quantified platforms. So you can see where you are against other, um, roles, similar to yours, other people, similar career paths, and see how you grow and, um, get better from there and to optimize your behavior. So who does it help? Um, it can help everybody, everybody can improve their lives, their personal lives, their professional lives, um, their business contacts, their ability to be able to sell and deliver products, um, through having better communications and being able to effectively deliver your message. This is fantastic for people in leadership programs who are looking to accelerate to senior executive executive positions, uh, who are looking to improve their status inside of an organization, their ability to be a leader and be inspiring, um, as well as entry level people who really want to represent their brand well, they wanna have a great impact on their external customer experience, as well as their internal ones. And this, this whole system can be tailored specifically for an organization so that we identify the key characteristics of your top sales leaders, your top performers, your top leaders, and replicate that across the rest of your organization. So it doesn't come with a one size fits all. It is very specific on thinking about the characteristics and the behavioral patterns and the communication styles of those who are already effective inside your organization and creating the patterns to duplicate that. So depending on, on your brand presence and what you value inside of your organization, that can be replicated at scale. So who's it gonna have the greatest impact on, um, those participating in customer experiences, those communicating with customers directly, um, uh, spending time with members of your team, inspiring them, providing leadership guidance, visibility into the overall vision of an organization. Um, there are so much science out there that says really effective leaders lead from great communication. Um, and we wanna remake those people remarkably better. Everybody can improve their communication and everybody deserves to be a great communicator. Um, we see growth early on in the process. So, um, as people participate in the program, they usually, uh, get about 30% better within their first six weeks to 12 weeks. So there's a huge uptick in ability to be able to become more trustworthy, authentic, credible, um, have better collective performances across your team and across your organization and have that individual growth as a team leader. Um, this is all based on evidence based research and a ton of analytics, which we're all very, very proud of. Uh, so I hope that explains our quantified platform. And I look forward to talking to you again soon. Thank you very much.\", 80 ],\n",
        "      [ \"Hi, everybody. I'm really excited to be first here to try this out. Not only do I get to go first and be the Guinea pig, but I also know that I will be first on the leaderboard. So tell me about quantified. What is it exactly quantified is an AI powered coaching platform. We are here to make people remarkably better communicators by combining behavioral science, artificial intelligence, and experiential learning to give them the experience of what the world's best communication coach would do with them. If they were sitting with them in every single conversation they had, we know that through our intelligence insights feedback, and we can help people go from not knowing where they stand, when it comes to being how they communicate to becoming exceptional, confident, and inspirational in the way that they communicate, build relationships and succeed professionally in their career. So how does it work? Quantified works by 10, the behaviors that you do, what you do with your voice, your face, your gestures, and your words, and understanding how that an audience is going to react to that we have essentially built a audience digital twin that predicts how people are going to respond to you when you speak. And the technology behind that is really complex, but what's important is the experience is actually pretty simple. We just need a video. So we need a three minute video from you. From those three minutes, we pull out 1400 behaviors and predict audience preference, give you feedback, give you coaching, give you guidance and support your learning journey. So you can go from where you are today to being exceptional in the way that you communicate and speak. Who's helped most by quantified. Well, everybody communicates all day as part of their jobs. We actually study that 80% of your time at work is spent communicating. So who's helped most anyone that talks to customers, anyone that talks to other team members, anyone that talks to people for a living is going to be helped the most, really the more that you communicate as a critical component of your job, the more you're gonna be helped. Finally, how can quantified have the greatest impact on my organization? Well, my organization is quantified, so that's a little bit of a strange answer for me, but, you know, I think directly even what we do for our customers is really important for us, right? Have to represent that we have to represent effective communication to each other and to our clients. And so quantified becoming an exceptional communicator, supporting each other and teaching teaching what great coaching looks like is something that every organization can benefit, certainly including us. And so I'm excited to bring this knowledge and this program to our ourselves and, um, you know, I'm really excited to kick it off. Uh, thank you for allowing me to be first here and let's see how these scores come out. Bye.\", 80 ],\n",
        "      [ \"Hi, so upfront caveat, this is going to be terrible. Um, personally, I need days to craft elegant wording, uh, and then more days to practice delivering that message. Um, and instead I'm extemporizing and so this is gonna read much more like a hostage video than marketing material that said dive in. So what is quantified, uh, quantified is the most advanced conversation intelligence and AI powered coaching platform, a software platform that helps people reach their potential, uh, for communicating and connecting empowered by behavioral science, which uses artificial intelligence to drive performance outcomes for customer facing teams, uh, which helps them sell more, which helps them deliver better experiences. How does it work? Um, it is integrated into video conference platforms in which you record yourself, uh, or respond to prompts with fun and realistic experiences. Um, that's all we need you to do, uh, have conversations like the types you have every day. We've built technology that looks at the words that you say, uh, what you do with your voice, your face, your gestures, simple input create, and we create benchmarking, scoring feedback, personalized guidance, and understand how you come across and relay to you how you're doing, uh, how you can get better coach you using in artificial intelligence as if the world's best communication coach. We're sitting there with you in every one of your conversations, uh, telling you how to get better and telling you how to optimize your behavior. So who does it help? Uh, it helps everyone that is having conversations, whether you're an entry level person or the most senior executive, the most powerful group that we can help our customer facing teams, sales teams, customer service teams, customer support, and customer success teams, anyone who is talking to the customer as a core part of their day to day job, uh, words that they use, the way that they present themselves, how they come across has an impact on the performance outcomes of the organization, giving coaching to them, coaching at scale that is standardized and scientific. It's hard to find time for managers to coach, and it is hard for us to give feedback. It's hard for people to feel empowered, to work on something that is personal and private in a safe space. Uh, how can it have the greatest impact, uh, customer experience communicating with the customer, spending time spending a lot of time, communicating with other members of your team, internal communication and external communication. Uh, we wanna make you remarkably better. We want to make you extraordinary at that behavior. Uh, that's meant to be learned along the way. Uh, no one at work can stop you for six months, 12 months, 18 months helping you become exceptional. This is your leadership journey. This is the most important skill for you. They don't have the time and they don't know how to do it. We can provide intentional guidance and deliver that on a personal basis for every single member of your organization that faces the customer. Um, make them 30% better at connecting with other people, measured by evidence based research, uh, the impact that could have on individual performance and your individual growth as a leader, collective performance of the teams in the organization, uh, and make you perceived as trustworthy, authentic, and credible, uh, and improves how you connect.\", 80 ],\n",
        "      [ \"My name's Johnny, thank you all so much for taking the time to chat with me today. I kinda wanna just to introduce, quantify, kind of give an overview of who we are and what problems we're trying to seek to solve here. So I'm gonna do this by simply answering four questions. The first of how does it work? Who does it help, who can have the greatest impact? Um, and by answering these questions, I think each of you will have a better understanding of who we are here at quantified. So just to get started, we are the most advanced conversations, intelligence and AI powered coaching platform. We're a software platform that helps people reach their utmost potential and for communicating and connecting with one another, we are empowered by behavioral research and science. So know that everything that we do is backed up by specific science and behavioral research. And we use a component of our artificial intelligence that really drives performance outcomes. And to customer facing teams, we help, for example, sales teams sell more. That's a, an ROI that we're able to capture and we help everyone just deliver overall better experiences to anyone that they're in con um, connection with how does it work? So there's a couple of ways that we can actually give you your objective, personalized feedback. One of which is having a video, um, conference platform integrated into your, um, everyday workflow. So things like zoom or teams, we can actually do real life, um, analysis there. Alternatively, you can record yourself. Um, we always try to give prompts with fun and realistic experiences, and that's all that we'll need to do have conversations like the types you have every day. And we've built that technology that looks at the words that you say, what you do with your voice, your face, your gestures, simple input, and we create benchmarks. That's able to give you that scoring feedback and that personalized guidance for you to be able to improve going forward. So you'll have a good understanding of how you come across a relay back to exactly how you're doing, how you can get better. Um, and coach you using that artificial intelligence. It's able to give you that objective feedback. It's gonna be exactly as if you have the world's best communications coach was sitting, um, there with you in every one of your conversations, telling you how to get better and telling you how to optimize your behavior, who does it help? So literally anyone that has conversations, if you're an entry level person, um, or if you're the most senior executive, you will benefit from our platform, the most powerful group that we can help our customer facing teams, that's sales teams, customer service teams, customer support, and customer success team. Literally anyone who is ha, who is talking to customer has a core part of their day to day job. The words that they use, the way that they present themselves, how they come across, um, that's exactly what we're going to look at and be able to give them coaching, um, based off of their daily interactions. Um, coaching them at a scale is the standardized and scientific. And it's hard to find time for managers to coach, right? So this is something that they're able to do whenever they need to prep for a conversation or, um, in their daily meetings as well. It's hard for people to feel empowered, to work on something that is personal and private. So this gives everyone a safe space to really work on something that's so impactful and so crucial to their day to day job functions. So how can it have the greatest impact customer experience, right? This is going to elevate the way, um, that individuals are communicating with the customer. It's allowing them to spend time on things that matters and impact their overall skillset. We spend 80% of our time communicating. Um, so it's something that we need to work on and progress forward with either other, um, members of your team, internal communication, external communication. We just want to make you remarkably better, right? We want to make your ex, we want to make the conversations that you're having extraordinary meant to be. This is meant to be learning along the way, right? Just like anything else that you do in life practice makes perfect. And this is no exception to that. Um, this is going to help prompt you in your leadership journey. This is the most important skill right now for you. Um, and that's how you're going to be able to perfect and move, um, forward. And through a year of using our platform, we're looking at 30% better at connecting with other people, um, and measured by evidence based research, which is absolutely amazing.\", 80 ]\n",
        "    ],\n",
        "    # #0B647B\n",
        "    css=\"body { background-color: white; background-image: url('file=https://res.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_256,w_256,f_auto,q_auto:eco,dpr_1/v1448402436/lwt1fdq69mdwal1jk894.png'); background-size: 100px 100px; background-repeat: no-repeat; background-position: 0px 0px; }\"\n",
        ")\n",
        "demo.launch() # debug=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "hygO7fOrn4N7",
        "outputId": "59de9b7c-28f2-4669-a12e-fd03e7aa188a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/outputs.py:128: UserWarning:\n",
            "\n",
            "Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://15264.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://15264.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7fc6499eaa50>,\n",
              " 'http://127.0.0.1:7881/',\n",
              " 'https://15264.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}